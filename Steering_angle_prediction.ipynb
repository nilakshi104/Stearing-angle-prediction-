{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Steering angle prediction.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nilakshi104/Steering-angle-prediction/blob/master/Steering_angle_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Juu6QaqjnU1F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "002bbacf-1202-4870-f4f3-80813bccb7aa"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChDhC0j3krEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#path for image='/content/drive/My Drive/ADAS1/IMG'\n",
        "#path for csv file='/content/drive/My Drive/ADAS1/driving_log.csv'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KN_eB-lySwip",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import scipy\n",
        "from scipy import signal\n",
        "import pandas as pd \n",
        "import torch\n",
        "from torch.utils import data\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import os\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "\n",
        "dataroot = '/content/drive/My Drive/Untitled folder/steer_pred/IMG/'\n",
        "dataroot1='/content/drive/My Drive/Untitled folder/steer_pred/'\n",
        "ckptroot = '/content/drive/My Drive/Untitled folder/steer_pred'\n",
        "\n",
        "#hyperparameters\n",
        "lr = 1e-4\n",
        "weight_decay = 1e-5\n",
        "batch_size = 32\n",
        "num_workers = 2\n",
        "train_size = 0.8\n",
        "shuffle = True\n",
        "\n",
        "epochs = 200\n",
        "start_epoch = 0\n",
        "resume = False\n",
        "\n",
        "# def toDevice(datas, device):\n",
        "#     \"\"\"Enable cuda.\"\"\"\n",
        "#     imgs, angles = datas\n",
        "#     return imgs.float().to(device), angles.float().to(device)\n",
        "#     # /content/drive/My Drive/ADAS1/driving_log.csv.gsheet/content/drive/My Drive/ADAS1/driving_log.gsheet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUpWjmi5p9Dj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def load_data(data_dir,test_size):\n",
        "  data_df=pd.read_csv(os.path.join(data_dir,'driving_log.csv'),names=['center', 'left', 'right', 'steering', 'throttle', 'reverse', 'speed'])\n",
        "   \n",
        "  data_df[\"steering\"] = signal.savgol_filter(data_df[\"steering\"].values.tolist(), 51, 11)\n",
        "\n",
        "  # Divide the data into training set and validation set\n",
        "  train_len = int(train_size * data_df.shape[0])\n",
        "  valid_len = data_df.shape[0] - train_len\n",
        "  trainset, valset = data.random_split(\n",
        "      data_df.values.tolist(), lengths=[train_len, valid_len])\n",
        "\n",
        "  return trainset, valset\n",
        "\n",
        "trainset, valset = load_data(dataroot1, train_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aMZXI5XiVBZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ee186ca3-ed75-4986-e196-832bc7f51130"
      },
      "source": [
        "trainset[0][3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.17207182919064376"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsnYJLkqI3cQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def augment(dataroot,imgName, angle):\n",
        "  name = dataroot + 'IMG/'+ imgName.split('\\\\')[-1]\n",
        "  current_image = cv2.imread(name)\n",
        "  if current_image is None:\n",
        "    print('image is not available ')\n",
        "  current_image = current_image[65:-25, :, :]\n",
        "  if np.random.rand() < 0.5:\n",
        "    current_image = cv2.flip(current_image, 1)\n",
        "    angle = angle * -1.0\n",
        "  return current_image, angle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KI7U5hj-vDYB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "eb0b1495-9883-42f9-f8de-05292df4a9c9"
      },
      "source": [
        "k=cv2.imread('/content/drive/My Drive/Untitled folder/steer_pred/IMG/center_2020_01_11_21_16_41_804.jpg')\n",
        "k = k[65:-25, :, :]\n",
        "k.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70, 320, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rq_qaYduYSgA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_set=[]\n",
        "for index in range(0,len(trainset)):\n",
        "  list1=[]\n",
        "  batch_samples = trainset[index]\n",
        "  steering_angle = float(batch_samples[3])\n",
        "\n",
        "  center_img, steering_angle_center = augment(dataroot1, batch_samples[0], steering_angle )\n",
        "  left_img, steering_angle_left     = augment (dataroot1 ,batch_samples[1], steering_angle+0.4)\n",
        "  right_img, steering_angle_right   =  augment (dataroot1, batch_samples[2], steering_angle-0.4)\n",
        "\n",
        "  list1.append((center_img, steering_angle_center))\n",
        "  list1.append((left_img, steering_angle_left))\n",
        "  list1.append((right_img, steering_angle_right))\n",
        "  training_set.append(list1)\n",
        "# training_set\n",
        "\n",
        "validation_set=[]\n",
        "for index in range(0,len(valset)):\n",
        "  list2=[]\n",
        "  batch_samples = valset[index]\n",
        "  steering_angle = float(batch_samples[3])\n",
        "\n",
        "  center_img, steering_angle_center = augment(dataroot1, batch_samples[0], steering_angle )\n",
        "  left_img, steering_angle_left     = augment (dataroot1 ,batch_samples[1], steering_angle+0.4)\n",
        "  right_img, steering_angle_right   =  augment (dataroot1, batch_samples[2], steering_angle-0.4)\n",
        "\n",
        "  list2.append((center_img, steering_angle_center))\n",
        "  list2.append((left_img, steering_angle_left))\n",
        "  list2.append((right_img, steering_angle_right))\n",
        "  validation_set.append(list2)\n",
        "# validation_set\n",
        "\n",
        "\n",
        "def toDevice(datas, device):\n",
        "    \"\"\"Enable cuda.\"\"\"\n",
        "    imgs, angles = datas\n",
        "    return imgs.float().to(device), angles.float().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-zLJFV301ZE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b26962a9-4f98-4cc1-b634-f300e16c2252"
      },
      "source": [
        "print(\"==> Preparing dataset ...\")\n",
        "def data_loader(training_set, validation_set, batch_size, shuffle, num_workers):\n",
        "    transformations = transforms.Compose([\n",
        "           transforms.ToTensor(),\n",
        "           transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "    # Load training data and validation data\n",
        "    trainloader = DataLoader(training_set,\n",
        "                             batch_size=batch_size,\n",
        "                             shuffle=shuffle,\n",
        "                             num_workers=num_workers)\n",
        "\n",
        "    # validation_set = TripletDataset(dataroot, valset, transformations)\n",
        "    valloader = DataLoader(validation_set,\n",
        "                           batch_size=batch_size,\n",
        "                           shuffle=shuffle,\n",
        "                           num_workers=num_workers)\n",
        "\n",
        "    return trainloader, valloader\n",
        "\n",
        "\n",
        "trainloader, validationloader= data_loader( training_set, validation_set,\n",
        "                                            batch_size,\n",
        "                                            shuffle,\n",
        "                                            num_workers)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Preparing dataset ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQSvQVC1GyZS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "2c95e7e6-76e7-4041-cf97-907b6e1a7c81"
      },
      "source": [
        "class NetworkNvidia(nn.Module):\n",
        "    \"\"\"NVIDIA model used in the paper.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize NVIDIA model.\n",
        "\n",
        "        NVIDIA model used\n",
        "            Image normalization to avoid saturation and make gradients work better.\n",
        "            Convolution: 5x5, filter: 24, strides: 2x2, activation: ELU\n",
        "            Convolution: 5x5, filter: 36, strides: 2x2, activation: ELU\n",
        "            Convolution: 5x5, filter: 48, strides: 2x2, activation: ELU\n",
        "            Convolution: 3x3, filter: 64, strides: 1x1, activation: ELU\n",
        "            Convolution: 3x3, filter: 64, strides: 1x1, activation: ELU\n",
        "            Drop out (0.5)\n",
        "            Fully connected: neurons: 100, activation: ELU\n",
        "            Fully connected: neurons: 50, activation: ELU\n",
        "            Fully connected: neurons: 10, activation: ELU\n",
        "            Fully connected: neurons: 1 (output)\n",
        "\n",
        "        the convolution layers are meant to handle feature engineering\n",
        "        the fully connected layer for predicting the steering angle.\n",
        "        \"\"\"\n",
        "        super(NetworkNvidia, self).__init__()\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(3, 24, 5, stride=2),\n",
        "            nn.ELU(),\n",
        "            nn.Conv2d(24, 36, 5, stride=2),\n",
        "            nn.ELU(),\n",
        "            nn.Conv2d(36, 48, 5, stride=2),\n",
        "            nn.ELU(),\n",
        "            nn.Conv2d(48, 64, 3),\n",
        "            nn.ELU(),\n",
        "            nn.Conv2d(64, 64, 3),\n",
        "            nn.Dropout(0.5)\n",
        "        )\n",
        "        self.linear_layers = nn.Sequential(\n",
        "            nn.Linear(in_features=64 * 2 * 33, out_features=100),\n",
        "            nn.ELU(),\n",
        "            nn.Linear(in_features=100, out_features=50),\n",
        "            nn.ELU(),\n",
        "            nn.Linear(in_features=50, out_features=10),\n",
        "            nn.Linear(in_features=10, out_features=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        \"\"\"Forward pass.\"\"\"\n",
        "        input = input.view(input.size(0), 3, 70, 320)\n",
        "        output = self.conv_layers(input)\n",
        "        # print(output.shape)\n",
        "        output = output.view(output.size(0), -1)\n",
        "        output = self.linear_layers(output)\n",
        "        return output\n",
        "\n",
        "\n",
        "# Define model\n",
        "print(\"==> Initialize model ...\")\n",
        "\n",
        "model = NetworkNvidia()\n",
        "\n",
        "print(\"==> Initialize model done ...\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Initialize model ...\n",
            "==> Initialize model done ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBR9cuNPbCXB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8a3ddc8c-bbd2-48c3-d34d-b4c0c6ec9e04"
      },
      "source": [
        "# Define optimizer and criterion\n",
        "optimizer = optim.Adam(model.parameters(),\n",
        "                       lr=lr,\n",
        "                       weight_decay=weight_decay)\n",
        "criterion = nn.MSELoss()\n",
        "scheduler = MultiStepLR(optimizer, milestones=[30, 50], gamma=0.1)\n",
        "\n",
        "# transfer to gpu\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axUbvYEpL_oA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for local_batch, (centers, lefts, rights) in enumerate(trainloader):\n",
        "#   if local_batch==0:\n",
        "#     datas = [centers, lefts, rights]\n",
        "#     for data in datas:\n",
        "#       imgs, angles = data\n",
        "#       # print(imgs)\n",
        "#       # print(angles.unsqueeze(1))\n",
        "#       outputs=model(imgs.float())\n",
        "#       ans=criterion(outputs,angles.unsqueeze(1).float())\n",
        "#       print(ans)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxHDIQ7QyaAc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Trainer(object):\n",
        "    \"\"\"Trainer.\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 ckptroot,\n",
        "                 model,\n",
        "                #  device,\n",
        "                 epochs,\n",
        "                 criterion,\n",
        "                 optimizer,\n",
        "                 scheduler,\n",
        "                 start_epoch,\n",
        "                 trainloader,\n",
        "                 validationloader):\n",
        "        \"\"\"Self-Driving car Trainer.\n",
        "\n",
        "        Args:\n",
        "            model:\n",
        "            device:\n",
        "            epochs:\n",
        "            criterion:\n",
        "            optimizer:\n",
        "            start_epoch:\n",
        "            trainloader:\n",
        "            validationloader:\n",
        "\n",
        "        \"\"\"\n",
        "        super(Trainer, self).__init__()\n",
        "\n",
        "        self.model = model\n",
        "        # self.device = device\n",
        "        self.epochs = epochs\n",
        "        self.ckptroot = ckptroot\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.scheduler = scheduler\n",
        "        self.start_epoch = start_epoch\n",
        "        self.trainloader = trainloader\n",
        "        self.validationloader = validationloader\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"Training process.\"\"\"\n",
        "        # self.model.to(self.device)\n",
        "        for epoch in range(self.start_epoch, self.epochs + self.start_epoch):\n",
        "            # Training\n",
        "            train_loss = 0.0\n",
        "            self.model.train()\n",
        "            for local_batch, (centers, lefts, rights) in enumerate(self.trainloader):\n",
        "                # centers, lefts, rights = toDevice(centers, self.device), toDevice(\n",
        "                #     lefts, self.device), toDevice(rights, self.device)\n",
        "                self.optimizer.zero_grad()\n",
        "                datas = [centers, lefts, rights]\n",
        "                for data in datas:\n",
        "                    imgs, angles = data\n",
        "                    # print(\"training image: \", imgs.shape)\n",
        "                    outputs = self.model(imgs)\n",
        "                    ## outpts=outputs.type(torch.LongTensor)\n",
        "                    loss = self.criterion(outputs, angles.unsqueeze(1).float())\n",
        "                    loss.backward()\n",
        "                    self.optimizer.step()\n",
        "                    train_loss += loss\n",
        "                if local_batch % 100 == 0:\n",
        "                  print(\"Training Epoch: {} | Loss: {}\".format(epoch, train_loss / (local_batch + 1)))\n",
        "\n",
        "            self.scheduler.step()\n",
        "\n",
        "            # Validation\n",
        "            self.model.eval()\n",
        "            valid_loss = 0\n",
        "            with torch.set_grad_enabled(False):\n",
        "                for local_batch, (centers, lefts, rights) in enumerate(self.validationloader):\n",
        "                    # centers, lefts, rights = toDevice(centers, self.device), toDevice(\n",
        "                    #     lefts, self.device), toDevice(rights, self.device)\n",
        "                    self.optimizer.zero_grad()\n",
        "                    datas = [centers, lefts, rights]\n",
        "                    for data in datas:\n",
        "                        imgs, angles = data\n",
        "                        outputs = self.model(imgs)\n",
        "                        loss = self.criterion(outputs, angles.unsqueeze(1).float())\n",
        "                        valid_loss += loss\n",
        "\n",
        "                    if local_batch % 100 == 0:\n",
        "                      print(\"Validation Loss: {}\".format(valid_loss / (local_batch + 1)))\n",
        "\n",
        "            print()\n",
        "            # Save model\n",
        "            if epoch >=198:\n",
        "\n",
        "                state = {\n",
        "                    'epoch': epoch + 1,\n",
        "                    'state_dict': self.model.state_dict(),\n",
        "                    'optimizer': self.optimizer.state_dict(),\n",
        "                    'scheduler': self.scheduler.state_dict(),\n",
        "                }\n",
        "\n",
        "                self.save_checkpoint(state)\n",
        "\n",
        "    def save_checkpoint(self, state):\n",
        "        \"\"\"Save checkpoint.\"\"\"\n",
        "        print(\"==> Save checkpoint ...\")\n",
        "        if not os.path.exists(self.ckptroot):\n",
        "            os.makedirs(self.ckptroot)\n",
        "\n",
        "        torch.save(state, self.ckptroot + 'steer_pred_model-{}.h5'.format(state['epoch']))\n",
        "           "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpSE7jPILmp2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "62fbdc49-aed3-4820-b8f4-a6d62dd68f5a"
      },
      "source": [
        "print(\"==> Start training ...\")\n",
        "trainer = Trainer(ckptroot,\n",
        "                  model,\n",
        "                  # device,\n",
        "                  epochs,\n",
        "                  criterion,\n",
        "                  optimizer,\n",
        "                  scheduler,\n",
        "                  start_epoch,\n",
        "                  trainloader,\n",
        "                  validationloader)\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Start training ...\n",
            "Training Epoch: 0 | Loss: 7.29891107766889e-05\n",
            "Validation Loss: 0.21145768160931766\n",
            "\n",
            "==> Save checkpoint ...\n",
            "Training Epoch: 1 | Loss: 0.00010292530532751698\n",
            "Validation Loss: 0.21817972871940583\n",
            "\n",
            "Training Epoch: 2 | Loss: 0.0001275957747566281\n",
            "Validation Loss: 0.22101195470895618\n",
            "\n",
            "Training Epoch: 3 | Loss: 0.00011032108341169078\n",
            "Validation Loss: 0.21697034465614706\n",
            "\n",
            "Training Epoch: 4 | Loss: 0.00011835017721750773\n",
            "Validation Loss: 0.22135543334297836\n",
            "\n",
            "Training Epoch: 5 | Loss: 7.824223530406016e-05\n",
            "Validation Loss: 0.21477255527861416\n",
            "\n",
            "==> Save checkpoint ...\n",
            "Training Epoch: 6 | Loss: 0.00015936781346681528\n",
            "Validation Loss: 0.21711772633716464\n",
            "\n",
            "Training Epoch: 7 | Loss: 0.00011791492124757497\n",
            "Validation Loss: 0.21643018745817244\n",
            "\n",
            "Training Epoch: 8 | Loss: 7.58652913646074e-05\n",
            "Validation Loss: 0.20645950292237103\n",
            "\n",
            "Training Epoch: 9 | Loss: 9.327893803856568e-05\n",
            "Validation Loss: 0.21724949800409377\n",
            "\n",
            "Training Epoch: 10 | Loss: 8.44368396428763e-05\n",
            "Validation Loss: 0.21565179654862732\n",
            "\n",
            "==> Save checkpoint ...\n",
            "Training Epoch: 11 | Loss: 0.00014139791073830565\n",
            "Validation Loss: 0.20925516006536782\n",
            "\n",
            "Training Epoch: 12 | Loss: 0.00010631776422087569\n",
            "Validation Loss: 0.2123134934809059\n",
            "\n",
            "Training Epoch: 13 | Loss: 0.00015152740797930164\n",
            "Validation Loss: 0.22474533319473267\n",
            "\n",
            "Training Epoch: 14 | Loss: 7.051535976643208e-05\n",
            "Validation Loss: 0.20568217185791582\n",
            "\n",
            "Training Epoch: 15 | Loss: 0.00012133424206695054\n",
            "Validation Loss: 0.21314870682545006\n",
            "\n",
            "==> Save checkpoint ...\n",
            "Training Epoch: 16 | Loss: 9.067877090274123e-05\n",
            "Validation Loss: 0.21304733585566282\n",
            "\n",
            "Training Epoch: 17 | Loss: 9.715714531921549e-05\n",
            "Validation Loss: 0.21898670739028603\n",
            "\n",
            "Training Epoch: 18 | Loss: 0.00010987881705659674\n",
            "Validation Loss: 0.22756896284408867\n",
            "\n",
            "Training Epoch: 19 | Loss: 0.00010556029519648291\n",
            "Validation Loss: 0.21748192608356476\n",
            "\n",
            "Training Epoch: 20 | Loss: 0.00010095438847201876\n",
            "Validation Loss: 0.21219146740622818\n",
            "\n",
            "==> Save checkpoint ...\n",
            "Training Epoch: 21 | Loss: 7.471965182048734e-05\n",
            "Validation Loss: 0.2195318378508091\n",
            "\n",
            "Training Epoch: 22 | Loss: 8.470497687085299e-05\n",
            "Validation Loss: 0.2123976011062041\n",
            "\n",
            "Training Epoch: 23 | Loss: 8.92394814400177e-05\n",
            "Validation Loss: 0.2123172702267766\n",
            "\n",
            "Training Epoch: 24 | Loss: 0.00010601676422083983\n",
            "Validation Loss: 0.21464272565208375\n",
            "\n",
            "Training Epoch: 25 | Loss: 0.00010540108269196935\n",
            "Validation Loss: 0.21205810958053917\n",
            "\n",
            "==> Save checkpoint ...\n",
            "Training Epoch: 26 | Loss: 0.00010891095280385343\n",
            "Validation Loss: 0.21772423991933465\n",
            "\n",
            "Training Epoch: 27 | Loss: 9.633737590775127e-05\n",
            "Validation Loss: 0.22525277803651989\n",
            "\n",
            "Training Epoch: 28 | Loss: 0.00011221655040571932\n",
            "Validation Loss: 0.21957336436025798\n",
            "\n",
            "Training Epoch: 29 | Loss: 9.96972739812918e-05\n",
            "Validation Loss: 0.21227375185117126\n",
            "\n",
            "Training Epoch: 30 | Loss: 7.217891015898203e-05\n",
            "Validation Loss: 0.21699582424480468\n",
            "\n",
            "==> Save checkpoint ...\n",
            "Training Epoch: 31 | Loss: 7.865248880989384e-05\n",
            "Validation Loss: 0.21683126268908381\n",
            "\n",
            "Training Epoch: 32 | Loss: 8.860732850735076e-05\n",
            "Validation Loss: 0.22091700229793787\n",
            "\n",
            "Training Epoch: 33 | Loss: 7.962497147673275e-05\n",
            "Validation Loss: 0.2175910654477775\n",
            "\n",
            "Training Epoch: 34 | Loss: 0.000115390924293024\n",
            "Validation Loss: 0.2204777131555602\n",
            "\n",
            "Training Epoch: 35 | Loss: 9.471435714658583e-05\n",
            "Validation Loss: 0.22037178312893957\n",
            "\n",
            "==> Save checkpoint ...\n",
            "Training Epoch: 36 | Loss: 6.937230045878096e-05\n",
            "Validation Loss: 0.22869719075970352\n",
            "\n",
            "Training Epoch: 37 | Loss: 0.00010938233208435122\n",
            "Validation Loss: 0.21912504523061216\n",
            "\n",
            "Training Epoch: 38 | Loss: 7.726268222540966e-05\n",
            "Validation Loss: 0.21463725622743368\n",
            "\n",
            "Training Epoch: 39 | Loss: 8.43472244014265e-05\n",
            "Validation Loss: 0.22552000591531396\n",
            "\n",
            "Training Epoch: 40 | Loss: 9.547080298943911e-05\n",
            "Validation Loss: 0.20627726905513555\n",
            "\n",
            "==> Save checkpoint ...\n",
            "Training Epoch: 41 | Loss: 7.106425073288847e-05\n",
            "Validation Loss: 0.208308445638977\n",
            "\n",
            "Training Epoch: 42 | Loss: 0.0001247536047230824\n",
            "Validation Loss: 0.21312525891698897\n",
            "\n",
            "Training Epoch: 43 | Loss: 5.9866167248401325e-05\n",
            "Validation Loss: 0.2134727663360536\n",
            "\n",
            "Training Epoch: 44 | Loss: 7.605555310874479e-05\n",
            "Validation Loss: 0.2184979545418173\n",
            "\n",
            "Training Epoch: 45 | Loss: 9.029526245285524e-05\n",
            "Validation Loss: 0.2125878338702023\n",
            "\n",
            "==> Save checkpoint ...\n",
            "Training Epoch: 46 | Loss: 6.613550931433565e-05\n",
            "Validation Loss: 0.2131808374542743\n",
            "\n",
            "Training Epoch: 47 | Loss: 0.00010645552538335323\n",
            "Validation Loss: 0.21480698813684285\n",
            "\n",
            "Training Epoch: 48 | Loss: 7.354381432378432e-05\n",
            "Validation Loss: 0.21998540754429996\n",
            "\n",
            "Training Epoch: 49 | Loss: 7.275196458067512e-05\n",
            "Validation Loss: 0.21532037702854723\n",
            "\n",
            "Training Epoch: 50 | Loss: 9.105109711526893e-05\n",
            "Validation Loss: 0.21486828196793795\n",
            "\n",
            "==> Save checkpoint ...\n",
            "Training Epoch: 51 | Loss: 6.737006151524838e-05\n",
            "Validation Loss: 0.21554598736111075\n",
            "\n",
            "Training Epoch: 52 | Loss: 6.305325041466858e-05\n",
            "Validation Loss: 0.22048043832182884\n",
            "\n",
            "Training Epoch: 53 | Loss: 8.388420110350125e-05\n",
            "Validation Loss: 0.22096882155165076\n",
            "\n",
            "Training Epoch: 54 | Loss: 5.295335085975239e-05\n",
            "Validation Loss: 0.2306807462591678\n",
            "\n",
            "Training Epoch: 55 | Loss: 7.27826809452381e-05\n",
            "Validation Loss: 0.20847253617830575\n",
            "\n",
            "==> Save checkpoint ...\n",
            "Training Epoch: 56 | Loss: 9.389598972120439e-05\n",
            "Validation Loss: 0.2159573386888951\n",
            "\n",
            "Training Epoch: 57 | Loss: 6.723131900798762e-05\n",
            "Validation Loss: 0.21576927369460464\n",
            "\n",
            "Training Epoch: 58 | Loss: 9.011857764562592e-05\n",
            "Validation Loss: 0.2148939826292917\n",
            "\n",
            "Training Epoch: 59 | Loss: 0.00011681044270517305\n",
            "Validation Loss: 0.22611761873122305\n",
            "\n",
            "Training Epoch: 60 | Loss: 6.615993606828852e-05\n",
            "Validation Loss: 0.21774009591899812\n",
            "\n",
            "==> Save checkpoint ...\n",
            "Training Epoch: 61 | Loss: 7.642597483936697e-05\n",
            "Validation Loss: 0.2170731839723885\n",
            "\n",
            "Training Epoch: 62 | Loss: 5.605781461781589e-05\n",
            "Validation Loss: 0.2282406878657639\n",
            "\n",
            "Training Epoch: 63 | Loss: 0.00010651987531673512\n",
            "Validation Loss: 0.2174450485035777\n",
            "\n",
            "Training Epoch: 64 | Loss: 8.351329051947687e-05\n",
            "Validation Loss: 0.21531227324157953\n",
            "\n",
            "Training Epoch: 65 | Loss: 8.68687211550423e-05\n",
            "Validation Loss: 0.21823275252245367\n",
            "\n",
            "==> Save checkpoint ...\n",
            "Training Epoch: 66 | Loss: 7.959132744872477e-05\n",
            "Validation Loss: 0.2111834331881255\n",
            "\n",
            "Training Epoch: 67 | Loss: 0.00010670385836419882\n",
            "Validation Loss: 0.21772385807707906\n",
            "\n",
            "Training Epoch: 68 | Loss: 6.821363967901561e-05\n",
            "Validation Loss: 0.21246988559141755\n",
            "\n",
            "Training Epoch: 69 | Loss: 0.00010982858566421783\n",
            "Validation Loss: 0.21877048315946013\n",
            "\n",
            "Training Epoch: 70 | Loss: 0.00012509271118688048\n",
            "Validation Loss: 0.21444661309942603\n",
            "\n",
            "==> Save checkpoint ...\n",
            "Training Epoch: 71 | Loss: 7.619782081746962e-05\n",
            "Validation Loss: 0.2269181462470442\n",
            "\n",
            "Training Epoch: 72 | Loss: 5.92488213442266e-05\n",
            "Validation Loss: 0.21911120135337114\n",
            "\n",
            "Training Epoch: 73 | Loss: 6.397277275027591e-05\n",
            "Validation Loss: 0.2179684677394107\n",
            "\n",
            "Training Epoch: 74 | Loss: 8.242226340371417e-05\n",
            "Validation Loss: 0.23802665737457573\n",
            "\n",
            "Training Epoch: 75 | Loss: 7.741838271613233e-05\n",
            "Validation Loss: 0.22869042539969087\n",
            "\n",
            "==> Save checkpoint ...\n",
            "Training Epoch: 76 | Loss: 8.125813883452793e-05\n",
            "Validation Loss: 0.23747732932679355\n",
            "\n",
            "Training Epoch: 77 | Loss: 5.893030265724519e-05\n",
            "Validation Loss: 0.1998946729581803\n",
            "\n",
            "Training Epoch: 78 | Loss: 9.442979580853716e-05\n",
            "Validation Loss: 0.21471480978652835\n",
            "\n",
            "Training Epoch: 79 | Loss: 6.808157149862382e-05\n",
            "Validation Loss: 0.22583795501850545\n",
            "\n",
            "==> Save checkpoint ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwtIJid2moB3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# class TripletDataset(data.Dataset):\n",
        "\n",
        "#     def __init__(self, data_root, samples, transform=None):\n",
        "#         self.samples = samples\n",
        "#         self.data_root = data_root\n",
        "#         self.transform = transform\n",
        "\n",
        "#     # def augment(self,imgName, angle):\n",
        "#     #     name = self.data_root + 'IMG/'+ imgName.split('\\\\')[-1]\n",
        "#     #     current_image = cv2.imread(name)\n",
        "#     #     if current_image is None:\n",
        "#     #       print('image is not available ')\n",
        "#     #     return current_image, angle\n",
        "\n",
        "#     def hh( self,index):\n",
        "#         batch_samples = self.samples[index]\n",
        "#         steering_angle = float(batch_samples[3])\n",
        "\n",
        "#         center_img, steering_angle_center =  batch_samples[0], steering_angle\n",
        "#         left_img, steering_angle_left     =  batch_samples[1], steering_angle+0.4\n",
        "#         right_img, steering_angle_right   =  batch_samples[2], steering_angle-0.4)\n",
        "\n",
        "#         # center_img = self.transform(center_img)\n",
        "#         # left_img   = self.transform(left_img)\n",
        "#         # right_img  = self.transform(right_img)\n",
        "\n",
        "#         return  (steering_angle_center), (steering_angle_left), (steering_angle_right)\n",
        "#         # return 1\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.samples)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}